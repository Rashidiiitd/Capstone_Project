{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDWQpN16zFIp"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CipyClBMzGhc"
      },
      "source": [
        "## Making Window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94HFYC2FzEkI",
        "outputId": "0776c714-efda-4cc8-e186-f6467e6f8f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Window size 21:\n",
            "                  Window  Label\n",
            "0  EHEEVAQRVIKLHRGRGVAAM      0\n",
            "1  SRQWVRDSCRKLSGLLRQKNA      0\n",
            "2  CRKLSGLLRQKNAVLNKLKTA      0\n",
            "3  LLRQKNAVLNKLKTAIGAVEK      0\n",
            "4  RQKNAVLNKLKTAIGAVEKDV      0\n",
            "Labeled windows have been saved to the corresponding folder.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('/content/Raw DataSet.csv')\n",
        "\n",
        "def parse_positive_sites(positive_sites_str):\n",
        "    \"\"\"Convert a space-separated string of positive sites into a list of integers.\"\"\"\n",
        "    try:\n",
        "        return list(map(int, positive_sites_str.split()))\n",
        "    except ValueError:\n",
        "        print(f\"Warning: Unable to parse positive sites from '{positive_sites_str}'\")\n",
        "        return []\n",
        "\n",
        "def generate_windows_and_labels(sequence, positivesites, window_size):\n",
        "    \"\"\"Generate windows centered on K and label them.\"\"\"\n",
        "    windows = []\n",
        "    labels = []\n",
        "\n",
        "    half_window = window_size // 2\n",
        "\n",
        "    for i in range(half_window, len(sequence) - half_window):\n",
        "        if sequence[i] == 'K':\n",
        "            window = sequence[i - half_window:i + half_window + 1]\n",
        "            label = 1 if (i + 1) in positivesites else 0\n",
        "            windows.append(window)\n",
        "            labels.append(label)\n",
        "\n",
        "    return windows, labels\n",
        "\n",
        "# Define the specific window size\n",
        "window_size = 21\n",
        "\n",
        "# Create a directory to save the CSV files\n",
        "output_dir = '/content/Window_21'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Initialize lists to store all windows and labels\n",
        "all_windows = []\n",
        "all_labels = []\n",
        "\n",
        "# Process each sequence in the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    sequence = row.get('Seq', '')\n",
        "    positivesites = parse_positive_sites(row.get('PositiveSite', ''))\n",
        "    if sequence and positivesites:\n",
        "        windows, labels = generate_windows_and_labels(sequence, positivesites, window_size)\n",
        "        all_windows.extend(windows)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "# Create a DataFrame with windows and labels\n",
        "windows_df = pd.DataFrame({'Window': all_windows, 'Label': all_labels})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_file_path = os.path.join(output_dir, f'labeled_windows_{window_size}.csv')\n",
        "windows_df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# Print the first few rows of the DataFrame\n",
        "print(f\"Window size {window_size}:\")\n",
        "print(windows_df.head())\n",
        "\n",
        "print(\"Labeled windows have been saved to the corresponding folder.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "XanMC6Q4upFe",
        "outputId": "912348f6-a2f0-4591-aaf5-2777c5d6bf65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_combined shape: (35400, 420)\n",
            "y_train shape: (35400,)\n",
            "X_test_combined shape: (8850, 420)\n",
            "y_test shape: (8850,)\n",
            "\n",
            "Random Forest Model Report:\n",
            "Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
            "Accuracy: 0.6662146892655367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-fb15802d7629>:88: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x='Model', y='Accuracy', data=report_df, palette='viridis')\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Fixed list of 20 standard amino acids\n",
        "amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "\n",
        "# Function to compute AAC features\n",
        "def aac_compute(seq):\n",
        "    seq = seq.replace('^', '')  # Remove '^' character if present\n",
        "    aa_counts = Counter(seq)\n",
        "    total_aa = len(seq)\n",
        "    aa_percentages = [(aa_counts[aa] / total_aa) * 100 if total_aa > 0 else 0 for aa in amino_acids]\n",
        "    return [round(v, 2) for v in aa_percentages]  # Round to two decimal places\n",
        "\n",
        "# Function to compute DPC features\n",
        "def dpc_compute(seq):\n",
        "    seq = seq.replace('^', '')  # Remove '^' character if present\n",
        "    total_pairs = len(seq) - 1\n",
        "    pair_counts = Counter([seq[i:i+2] for i in range(len(seq)-1)])\n",
        "    pair_frequencies = [(pair_counts[aa1+aa2] / total_pairs) * 100 if total_pairs > 0 else 0 for aa1 in amino_acids for aa2 in amino_acids]\n",
        "    return [round(v, 2) for v in pair_frequencies]  # Round to two decimal places\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    predictions = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    return accuracy\n",
        "\n",
        "# Load your training dataset\n",
        "train_data = pd.read_csv('/content/training_set_21.csv')\n",
        "\n",
        "# Extract sequences and labels for training\n",
        "X_train = train_data['Window']\n",
        "y_train = train_data['Label']\n",
        "\n",
        "# Drop rows where y is NaN\n",
        "X_train = X_train[~y_train.isna()]\n",
        "y_train = y_train.dropna()\n",
        "\n",
        "# Compute AAC and DPC features for each sequence in X_train\n",
        "X_train_aac = np.array(X_train.apply(aac_compute).tolist())\n",
        "X_train_dpc = np.array(X_train.apply(dpc_compute).tolist())\n",
        "X_train_combined = np.concatenate((X_train_aac, X_train_dpc), axis=1)\n",
        "\n",
        "print(\"X_train_combined shape:\", X_train_combined.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "\n",
        "# Load your test dataset\n",
        "test_data = pd.read_csv('/content/test_set_21.csv')\n",
        "\n",
        "# Extract sequences and labels for testing\n",
        "X_test = test_data['Window']\n",
        "y_test = test_data['Label']\n",
        "\n",
        "# Compute AAC and DPC features for each sequence in X_test\n",
        "X_test_aac = np.array(X_test.apply(aac_compute).tolist())\n",
        "X_test_dpc = np.array(X_test.apply(dpc_compute).tolist())\n",
        "X_test_combined = np.concatenate((X_test_aac, X_test_dpc), axis=1)\n",
        "\n",
        "print(\"X_test_combined shape:\", X_test_combined.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# Define the Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "\n",
        "# Train the model on the combined features\n",
        "model.fit(X_train_combined, y_train)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "accuracy = evaluate_model(model, X_test_combined, y_test)\n",
        "\n",
        "# Print the model report\n",
        "print(f\"\\nRandom Forest Model Report:\")\n",
        "print(f\"Parameters: {model.get_params()}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Create a DataFrame for the model report\n",
        "report_df = pd.DataFrame({'Model': ['Random Forest'], 'Accuracy': [accuracy]})\n",
        "\n",
        "# Plot the accuracy\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x='Model', y='Accuracy', data=report_df, palette='viridis')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# Save the report to a CSV file\n",
        "report_df.to_csv('model_report_table.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ5JAX_0wdiD",
        "outputId": "5c1c360b-ddc4-4d50-8ddf-afb6de2c1621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (24542, 2), Training labels shape: (24542,)\n",
            "Test data shape: (6136, 2), Test labels shape: (6136,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/labeled_windows_21.csv')\n",
        "\n",
        "# Extract sequences and labels\n",
        "X = data['Window']\n",
        "y = data['Label']\n",
        "\n",
        "# Combine features and labels into a single DataFrame\n",
        "data = pd.DataFrame({'Window': X, 'Label': y})\n",
        "\n",
        "# Separate data by class\n",
        "class_0 = data[data['Label'] == 0]\n",
        "class_1 = data[data['Label'] == 1]\n",
        "\n",
        "# Find the number of samples in each class\n",
        "num_class_0 = len(class_0)\n",
        "num_class_1 = len(class_1)\n",
        "\n",
        "# Determine the desired class sizes for a 2:1 ratio\n",
        "desired_class_1_size = num_class_1\n",
        "desired_class_0_size = 2 * desired_class_1_size\n",
        "\n",
        "# Sample the data to achieve the desired ratio\n",
        "if desired_class_0_size > num_class_0:\n",
        "    print(f\"Warning: Not enough class_0 samples. Reducing to maximum available ({num_class_0})\")\n",
        "    desired_class_0_size = num_class_0\n",
        "\n",
        "class_0_balanced = class_0.sample(n=desired_class_0_size, random_state=42)\n",
        "class_1_balanced = class_1.sample(n=desired_class_1_size, random_state=42)\n",
        "\n",
        "# Combine the balanced data\n",
        "balanced_data = pd.concat([class_0_balanced, class_1_balanced])\n",
        "\n",
        "# Shuffle the balanced dataset\n",
        "balanced_data = shuffle(balanced_data, random_state=42)\n",
        "\n",
        "# Extract balanced features and labels\n",
        "X_balanced = balanced_data['Window']\n",
        "y_balanced = balanced_data['Label']\n",
        "\n",
        "# Split the balanced dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
        "\n",
        "# Combine features and labels for saving\n",
        "train_set = pd.DataFrame({'Window': X_train, 'Label': y_train})\n",
        "test_set = pd.DataFrame({'Window': X_test, 'Label': y_test})\n",
        "\n",
        "# Save the datasets to CSV files\n",
        "train_set.to_csv('/content/training_set_21.csv', index=False)\n",
        "test_set.to_csv('/content/test_set_21.csv', index=False)\n",
        "\n",
        "# Print shapes of resulting sets\n",
        "print(f\"Training data shape: {train_set.shape}, Training labels shape: {train_set['Label'].shape}\")\n",
        "print(f\"Test data shape: {test_set.shape}, Test labels shape: {test_set['Label'].shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW2oXHK63E2T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDce_5EM3FZn"
      },
      "source": [
        "## Multiple Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDF-2czh3HNa",
        "outputId": "ac5c6a4c-249f-40b8-b2d1-e119c1b5dea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_combined shape: (24542, 420)\n",
            "y_train shape: (24542,)\n",
            "X_test_combined shape: (6136, 420)\n",
            "y_test shape: (6136,)\n",
            "192/192 [==============================] - 0s 2ms/step\n",
            "Random Forest Accuracy: 0.6760104302477183\n",
            "KNN Accuracy: 0.6577574967405476\n",
            "XGBoost Accuracy: 0.6808996088657105\n",
            "DNN Accuracy: 0.6395045632333768\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "import tensorflow as tf\n",
        "\n",
        "# Fixed list of 20 standard amino acids\n",
        "amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "\n",
        "# Function to compute AAC features\n",
        "def aac_compute(seq):\n",
        "    seq = seq.replace('^', '')  # Remove '^' character if present\n",
        "    aa_counts = Counter(seq)\n",
        "    total_aa = len(seq)\n",
        "    aa_percentages = [(aa_counts[aa] / total_aa) * 100 if total_aa > 0 else 0 for aa in amino_acids]\n",
        "    return [round(v, 2) for v in aa_percentages]  # Round to two decimal places\n",
        "\n",
        "# Function to compute DPC features\n",
        "def dpc_compute(seq):\n",
        "    seq = seq.replace('^', '')  # Remove '^' character if present\n",
        "    total_pairs = len(seq) - 1\n",
        "    pair_counts = Counter([seq[i:i+2] for i in range(len(seq)-1)])\n",
        "    pair_frequencies = [(pair_counts[aa1+aa2] / total_pairs) * 100 if total_pairs > 0 else 0 for aa1 in amino_acids for aa2 in amino_acids]\n",
        "    return [round(v, 2) for v in pair_frequencies]  # Round to two decimal places\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    predictions = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    return accuracy\n",
        "\n",
        "# Load your training dataset\n",
        "train_data = pd.read_csv('/content/training_set_21.csv')\n",
        "\n",
        "# Extract sequences and labels for training\n",
        "X_train = train_data['Window']\n",
        "y_train = train_data['Label']\n",
        "\n",
        "# Drop rows where y is NaN\n",
        "X_train = X_train[~y_train.isna()]\n",
        "y_train = y_train.dropna()\n",
        "\n",
        "# Compute AAC and DPC features for each sequence in X_train\n",
        "X_train_aac = np.array(X_train.apply(aac_compute).tolist())\n",
        "X_train_dpc = np.array(X_train.apply(dpc_compute).tolist())\n",
        "X_train_combined = np.concatenate((X_train_aac, X_train_dpc), axis=1)\n",
        "\n",
        "print(\"X_train_combined shape:\", X_train_combined.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "\n",
        "# Load your test dataset\n",
        "test_data = pd.read_csv('/content/test_set_21.csv')\n",
        "\n",
        "# Extract sequences and labels for testing\n",
        "X_test = test_data['Window']\n",
        "y_test = test_data['Label']\n",
        "\n",
        "# Compute AAC and DPC features for each sequence in X_test\n",
        "X_test_aac = np.array(X_test.apply(aac_compute).tolist())\n",
        "X_test_dpc = np.array(X_test.apply(dpc_compute).tolist())\n",
        "X_test_combined = np.concatenate((X_test_aac, X_test_dpc), axis=1)\n",
        "\n",
        "print(\"X_test_combined shape:\", X_test_combined.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# Initialize and train a RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "rf_classifier.fit(X_train_combined, y_train)\n",
        "\n",
        "# Initialize and train a KNeighborsClassifier with grid search for hyperparameter tuning\n",
        "knn_param_grid = {'n_neighbors': list(range(3, 10))}\n",
        "knn_grid_search = GridSearchCV(KNeighborsClassifier(), knn_param_grid)\n",
        "knn_grid_search.fit(X_train_combined, y_train)\n",
        "knn_model = knn_grid_search.best_estimator_\n",
        "\n",
        "# Initialize and train an XGBClassifier\n",
        "xgb_model = XGBClassifier()\n",
        "xgb_model.fit(X_train_combined, y_train)\n",
        "\n",
        "# Define and train the DNN model\n",
        "dnn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_combined.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')  # Assuming 2 classes for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "dnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',  # Use 'sparse_categorical_crossentropy' for integer labels\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = dnn_model.fit(X_train_combined, y_train, epochs=80, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "# Predict labels for test data\n",
        "rf_pred = rf_classifier.predict(X_test_combined)\n",
        "knn_pred = knn_model.predict(X_test_combined)\n",
        "xgb_pred = xgb_model.predict(X_test_combined)\n",
        "dnn_pred = np.argmax(dnn_model.predict(X_test_combined), axis=-1)\n",
        "\n",
        "# Evaluate model performance using accuracy_score\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
        "dnn_accuracy = accuracy_score(y_test, dnn_pred)\n",
        "\n",
        "# Print accuracy scores for each model\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
        "print(f\"KNN Accuracy: {knn_accuracy}\")\n",
        "print(f\"XGBoost Accuracy: {xgb_accuracy}\")\n",
        "print(f\"DNN Accuracy: {dnn_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUIWAo5Yoy3L",
        "outputId": "cbaa3e0d-0c49-4103-ab40-cf95e392d7cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_combined shape: (24542, 420)\n",
            "y_train shape: (24542,)\n",
            "X_test_combined shape: (6136, 420)\n",
            "y_test shape: (6136,)\n",
            "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Fixed list of 20 standard amino acids\n",
        "amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "\n",
        "# Function to compute AAC features\n",
        "def aac_compute(seq):\n",
        "    seq = seq.replace('^', '')  # Remove '^' character if present\n",
        "    aa_counts = Counter(seq)\n",
        "    total_aa = len(seq)\n",
        "    aa_percentages = [(aa_counts[aa] / total_aa) * 100 if total_aa > 0 else 0 for aa in amino_acids]\n",
        "    return [round(v, 2) for v in aa_percentages]  # Round to two decimal places\n",
        "\n",
        "# Function to compute DPC features\n",
        "def dpc_compute(seq):\n",
        "    seq = seq.replace('^', '')  # Remove '^' character if present\n",
        "    total_pairs = len(seq) - 1\n",
        "    pair_counts = Counter([seq[i:i+2] for i in range(len(seq)-1)])\n",
        "    pair_frequencies = [(pair_counts[aa1+aa2] / total_pairs) * 100 if total_pairs > 0 else 0 for aa1 in amino_acids for aa2 in amino_acids]\n",
        "    return [round(v, 2) for v in pair_frequencies]  # Round to two decimal places\n",
        "\n",
        "# Load your training dataset\n",
        "train_data = pd.read_csv('/content/training_set_21.csv')\n",
        "\n",
        "# Extract sequences and labels for training\n",
        "X_train = train_data['Window']\n",
        "y_train = train_data['Label']\n",
        "\n",
        "# Drop rows where y is NaN\n",
        "X_train = X_train[~y_train.isna()]\n",
        "y_train = y_train.dropna()\n",
        "\n",
        "# Compute AAC and DPC features for each sequence in X_train\n",
        "X_train_aac = np.array(X_train.apply(aac_compute).tolist())\n",
        "X_train_dpc = np.array(X_train.apply(dpc_compute).tolist())\n",
        "X_train_combined = np.concatenate((X_train_aac, X_train_dpc), axis=1)\n",
        "\n",
        "print(\"X_train_combined shape:\", X_train_combined.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "\n",
        "# Load your test dataset\n",
        "test_data = pd.read_csv('/content/test_set_21.csv')\n",
        "\n",
        "# Extract sequences and labels for testing\n",
        "X_test = test_data['Window']\n",
        "y_test = test_data['Label']\n",
        "\n",
        "# Compute AAC and DPC features for each sequence in X_test\n",
        "X_test_aac = np.array(X_test.apply(aac_compute).tolist())\n",
        "X_test_dpc = np.array(X_test.apply(dpc_compute).tolist())\n",
        "X_test_combined = np.concatenate((X_test_aac, X_test_dpc), axis=1)\n",
        "\n",
        "print(\"X_test_combined shape:\", X_test_combined.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_depth': [10, 20, 30, 40, 50, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize the RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train_combined, y_train)\n",
        "\n",
        "# Get the best estimator\n",
        "best_rf_classifier = grid_search.best_estimator_\n",
        "\n",
        "# Predict labels for test data using the best model\n",
        "rf_pred = best_rf_classifier.predict(X_test_combined)\n",
        "\n",
        "# Evaluate model performance using accuracy_score\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "\n",
        "# Print the best parameters and accuracy score\n",
        "print(f\"Best Random Forest Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37RHjtMLo7QD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Fixed list of 20 standard amino acids\n",
        "amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "\n",
        "# Function to compute AAC features\n",
        "def aac_compute(seq):\n",
        "    seq = seq.replace('^', '')  # Remove '^' character if present\n",
        "    aa_counts = Counter(seq)\n",
        "    total_aa = len(seq)\n",
        "    aa_percentages = [(aa_counts[aa] / total_aa) * 100 if total_aa > 0 else 0 for aa in amino_acids]\n",
        "    return [round(v, 2) for v in aa_percentages]  # Round to two decimal places\n",
        "\n",
        "# Function to compute DPC features\n",
        "def dpc_compute(seq):\n",
        "    seq = seq.replace('^', '')  # Remove '^' character if present\n",
        "    total_pairs = len(seq) - 1\n",
        "    pair_counts = Counter([seq[i:i+2] for i in range(len(seq)-1)])\n",
        "    pair_frequencies = [(pair_counts[aa1+aa2] / total_pairs) * 100 if total_pairs > 0 else 0 for aa1 in amino_acids for aa2 in amino_acids]\n",
        "    return [round(v, 2) for v in pair_frequencies]  # Round to two decimal places\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    predictions = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    return accuracy\n",
        "\n",
        "# Load your training dataset\n",
        "train_data = pd.read_csv('/content/training_set_21.csv')\n",
        "\n",
        "# Extract sequences and labels for training\n",
        "X_train = train_data['Window']\n",
        "y_train = train_data['Label']\n",
        "\n",
        "# Drop rows where y is NaN\n",
        "X_train = X_train[~y_train.isna()]\n",
        "y_train = y_train.dropna()\n",
        "\n",
        "# Compute AAC features for each sequence in X_train\n",
        "X_train_aac = np.array(X_train.apply(aac_compute).tolist())\n",
        "\n",
        "# Compute DPC features for each sequence in X_train\n",
        "X_train_dpc = np.array(X_train.apply(dpc_compute).tolist())\n",
        "\n",
        "# Load your test dataset\n",
        "test_data = pd.read_csv('/content/test_set_21.csv')\n",
        "\n",
        "# Extract sequences and labels for testing\n",
        "X_test = test_data['Window']\n",
        "y_test = test_data['Label']\n",
        "\n",
        "# Compute AAC features for each sequence in X_test\n",
        "X_test_aac = np.array(X_test.apply(aac_compute).tolist())\n",
        "\n",
        "# Compute DPC features for each sequence in X_test\n",
        "X_test_dpc = np.array(X_test.apply(dpc_compute).tolist())\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_depth': [10, 20, 30, 40, 50, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Function to perform GridSearchCV and evaluate the model\n",
        "def train_and_evaluate_rf(X_train, y_train, X_test, y_test, param_grid):\n",
        "    rf_classifier = RandomForestClassifier()\n",
        "    grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_rf_classifier = grid_search.best_estimator_\n",
        "    rf_pred = best_rf_classifier.predict(X_test)\n",
        "    rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "    print(f\"Best Random Forest Parameters: {grid_search.best_params_}\")\n",
        "    return rf_accuracy\n",
        "\n",
        "# Evaluate model with AAC features\n",
        "print(\"Evaluating model with AAC features...\")\n",
        "rf_accuracy_aac = train_and_evaluate_rf(X_train_aac, y_train, X_test_aac, y_test, param_grid)\n",
        "print(f\"Random Forest Accuracy with AAC features: {rf_accuracy_aac}\")\n",
        "\n",
        "# Evaluate model with DPC features\n",
        "print(\"Evaluating model with DPC features...\")\n",
        "rf_accuracy_dpc = train_and_evaluate_rf(X_train_dpc, y_train, X_test_dpc, y_test, param_grid)\n",
        "print(f\"Random Forest Accuracy with DPC features: {rf_accuracy_dpc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ACCURACY USING EACH Feature Extraction Technique"
      ],
      "metadata": {
        "id": "HhPhBO-ftbQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Fixed list of 20 standard amino acids\n",
        "amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "\n",
        "# Function to compute AAC features\n",
        "def aac_compute(seq):\n",
        "    seq = str(seq).replace('^', '')  # Convert to string and remove '^' character if present\n",
        "    aa_counts = Counter(seq)\n",
        "    total_aa = len(seq)\n",
        "    aa_percentages = [(aa_counts[aa] / total_aa) * 100 if total_aa > 0 else 0 for aa in amino_acids]\n",
        "    return [round(v, 2) for v in aa_percentages]  # Round to two decimal places\n",
        "\n",
        "# Function to compute DPC features\n",
        "def dpc_compute(seq):\n",
        "    seq = str(seq).replace('^', '')  # Convert to string and remove '^' character if present\n",
        "    total_pairs = len(seq) - 1\n",
        "    pair_counts = Counter([seq[i:i+2] for i in range(len(seq)-1)])\n",
        "    pair_frequencies = [(pair_counts[aa1+aa2] / total_pairs) * 100 if total_pairs > 0 else 0 for aa1 in amino_acids for aa2 in amino_acids]\n",
        "    return [round(v, 2) for v in pair_frequencies]  # Round to two decimal places\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    predictions = model.predict(X_test)\n",
        "    return accuracy_score(y_test, predictions), f1_score(y_test, predictions, average='macro')\n",
        "\n",
        "# Function to create DNN model\n",
        "def create_dnn(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/training_set_21.csv')\n",
        "\n",
        "# Extract sequences and labels\n",
        "X = data['Window'].astype(str)\n",
        "y = data['Label']\n",
        "\n",
        "# Compute AAC and DPC features for each sequence\n",
        "X_aac = np.array([aac_compute(seq) for seq in X])\n",
        "X_dpc = np.array([dpc_compute(seq) for seq in X])\n",
        "\n",
        "# One-Hot Encoding\n",
        "onehot_encoder = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "X_onehot = onehot_encoder.fit_transform(X).toarray()\n",
        "\n",
        "# TF-IDF Encoding\n",
        "tfidf_encoder = TfidfVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "X_tfidf = tfidf_encoder.fit_transform(X).toarray()\n",
        "\n",
        "# Bag of Words\n",
        "bow_encoder = CountVectorizer(analyzer='char', ngram_range=(2, 2))  # Using bigrams for BoW\n",
        "X_bow = bow_encoder.fit_transform(X).toarray()\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train_aac, X_test_aac, y_train, y_test = train_test_split(X_aac, y, test_size=0.2, random_state=42)\n",
        "X_train_dpc, X_test_dpc, _, _ = train_test_split(X_dpc, y, test_size=0.2, random_state=42)\n",
        "X_train_onehot, X_test_onehot, _, _ = train_test_split(X_onehot, y, test_size=0.2, random_state=42)\n",
        "X_train_tfidf, X_test_tfidf, _, _ = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "X_train_bow, X_test_bow, _, _ = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model definitions and hyperparameters\n",
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    'RandomForest': {'n_estimators': [100], 'max_depth': [10, 12]},\n",
        "    'KNN': {'n_neighbors': [3, 5, 7, 9]},\n",
        "    'XGBoost': {'n_estimators': [100], 'max_depth': [10, 12]}\n",
        "}\n",
        "\n",
        "# Function to train and evaluate models on a specific feature set\n",
        "def train_evaluate_feature_set(X_train, X_test, y_train, y_test, feature_name):\n",
        "    results = {}\n",
        "    for model_name, model in models.items():\n",
        "        grid_search = GridSearchCV(model, param_grids[model_name], scoring='accuracy', cv=5)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_model = grid_search.best_estimator_\n",
        "        accuracy, f1 = evaluate_model(best_model, X_test, y_test)\n",
        "        results[model_name] = {'accuracy': accuracy, 'f1_score': f1}\n",
        "        print(f\"{model_name} Best Params: {grid_search.best_params_}\")\n",
        "        print(f\"{model_name} Accuracy ({feature_name}): {accuracy}\")\n",
        "        print(f\"{model_name} F1 Score ({feature_name}): {f1}\")\n",
        "\n",
        "    # Train and evaluate DNN model\n",
        "    input_dim = X_train.shape[1]\n",
        "    dnn_model = create_dnn(input_dim)\n",
        "    dnn_model.fit(X_train, y_train, epochs=80, batch_size=32, validation_split=0.2, verbose=1)\n",
        "    dnn_predictions = np.argmax(dnn_model.predict(X_test), axis=1)\n",
        "    dnn_accuracy = accuracy_score(y_test, dnn_predictions)\n",
        "    dnn_f1 = f1_score(y_test, dnn_predictions, average='macro')\n",
        "    results['DNN'] = {'accuracy': dnn_accuracy, 'f1_score': dnn_f1}\n",
        "    print(f\"DNN Accuracy ({feature_name}): {dnn_accuracy}\")\n",
        "    print(f\"DNN F1 Score ({feature_name}): {dnn_f1}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Train and evaluate models on each feature set\n",
        "results_aac = train_evaluate_feature_set(X_train_aac, X_test_aac, y_train, y_test, 'AAC')\n",
        "results_dpc = train_evaluate_feature_set(X_train_dpc, X_test_dpc, y_train, y_test, 'DPC')\n",
        "results_onehot = train_evaluate_feature_set(X_train_onehot, X_test_onehot, y_train, y_test, 'One-Hot')\n",
        "results_tfidf = train_evaluate_feature_set(X_train_tfidf, X_test_tfidf, y_train, y_test, 'TF-IDF')\n",
        "results_bow = train_evaluate_feature_set(X_train_bow, X_test_bow, y_train, y_test, 'Bag of Words')\n",
        "\n",
        "# Combine all results into a DataFrame for visualization\n",
        "all_results = []\n",
        "for feature, results in zip(['AAC', 'DPC', 'One-Hot', 'TF-IDF', 'Bag of Words'],\n",
        "                            [results_aac, results_dpc, results_onehot, results_tfidf, results_bow]):\n",
        "    for model_name, metrics in results.items():\n",
        "        all_results.append({'Feature': feature, 'Model': model_name, 'Accuracy': metrics['accuracy'], 'F1_Score': metrics['f1_score']})\n",
        "\n",
        "results_df = pd.DataFrame(all_results)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Feature', y='Accuracy', hue='Model', data=results_df, palette='viridis')\n",
        "plt.title('Model Accuracies by Feature Type')\n",
        "plt.xlabel('Feature Type')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Feature', y='F1_Score', hue='Model', data=results_df, palette='viridis')\n",
        "plt.title('Model F1 Scores by Feature Type')\n",
        "plt.xlabel('Feature Type')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv('model_accuracies_f1_scores.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jjk2doPmtajv",
        "outputId": "b34a0fe5-9c7d-4073-c9c2-b0c6966c9db8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest Best Params: {'max_depth': 12, 'n_estimators': 100}\n",
            "RandomForest Accuracy (AAC): 0.6746791607251986\n",
            "RandomForest F1 Score (AAC): 0.4661680440990825\n",
            "KNN Best Params: {'n_neighbors': 9}\n",
            "KNN Accuracy (AAC): 0.628844978610715\n",
            "KNN F1 Score (AAC): 0.5373561149367354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:00:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:00:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:00:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:00:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:00:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:00:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:00:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:00:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:00:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:00:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:00:53] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Best Params: {'max_depth': 10, 'n_estimators': 100}\n",
            "XGBoost Accuracy (AAC): 0.6549195355469546\n",
            "XGBoost F1 Score (AAC): 0.5755305252085227\n",
            "Epoch 1/80\n",
            "491/491 [==============================] - 3s 3ms/step - loss: 0.8910 - accuracy: 0.6071 - val_loss: 0.6274 - val_accuracy: 0.6751\n",
            "Epoch 2/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.6378 - accuracy: 0.6573 - val_loss: 0.6202 - val_accuracy: 0.6751\n",
            "Epoch 3/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.6247 - accuracy: 0.6623 - val_loss: 0.6141 - val_accuracy: 0.6751\n",
            "Epoch 4/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.6174 - accuracy: 0.6633 - val_loss: 0.6088 - val_accuracy: 0.6751\n",
            "Epoch 5/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.6131 - accuracy: 0.6629 - val_loss: 0.6089 - val_accuracy: 0.6751\n",
            "Epoch 6/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.6090 - accuracy: 0.6629 - val_loss: 0.6027 - val_accuracy: 0.6751\n",
            "Epoch 7/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.6050 - accuracy: 0.6645 - val_loss: 0.5952 - val_accuracy: 0.6751\n",
            "Epoch 8/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.6006 - accuracy: 0.6640 - val_loss: 0.5945 - val_accuracy: 0.6758\n",
            "Epoch 9/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.6008 - accuracy: 0.6652 - val_loss: 0.5895 - val_accuracy: 0.6766\n",
            "Epoch 10/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5939 - accuracy: 0.6703 - val_loss: 0.5872 - val_accuracy: 0.6804\n",
            "Epoch 11/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5927 - accuracy: 0.6703 - val_loss: 0.5884 - val_accuracy: 0.6825\n",
            "Epoch 12/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5910 - accuracy: 0.6706 - val_loss: 0.5860 - val_accuracy: 0.6779\n",
            "Epoch 13/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5906 - accuracy: 0.6711 - val_loss: 0.5879 - val_accuracy: 0.6791\n",
            "Epoch 14/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5886 - accuracy: 0.6739 - val_loss: 0.5861 - val_accuracy: 0.6812\n",
            "Epoch 15/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5875 - accuracy: 0.6688 - val_loss: 0.5864 - val_accuracy: 0.6791\n",
            "Epoch 16/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5870 - accuracy: 0.6696 - val_loss: 0.5865 - val_accuracy: 0.6812\n",
            "Epoch 17/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5867 - accuracy: 0.6727 - val_loss: 0.5861 - val_accuracy: 0.6776\n",
            "Epoch 18/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5844 - accuracy: 0.6764 - val_loss: 0.5873 - val_accuracy: 0.6797\n",
            "Epoch 19/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5855 - accuracy: 0.6717 - val_loss: 0.5872 - val_accuracy: 0.6850\n",
            "Epoch 20/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5824 - accuracy: 0.6803 - val_loss: 0.5834 - val_accuracy: 0.6853\n",
            "Epoch 21/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5820 - accuracy: 0.6743 - val_loss: 0.5834 - val_accuracy: 0.6850\n",
            "Epoch 22/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5807 - accuracy: 0.6782 - val_loss: 0.5858 - val_accuracy: 0.6858\n",
            "Epoch 23/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5786 - accuracy: 0.6764 - val_loss: 0.5901 - val_accuracy: 0.6794\n",
            "Epoch 24/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5783 - accuracy: 0.6796 - val_loss: 0.5863 - val_accuracy: 0.6812\n",
            "Epoch 25/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5814 - accuracy: 0.6779 - val_loss: 0.5863 - val_accuracy: 0.6789\n",
            "Epoch 26/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5761 - accuracy: 0.6791 - val_loss: 0.5864 - val_accuracy: 0.6817\n",
            "Epoch 27/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5764 - accuracy: 0.6806 - val_loss: 0.5886 - val_accuracy: 0.6837\n",
            "Epoch 28/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5764 - accuracy: 0.6827 - val_loss: 0.5874 - val_accuracy: 0.6850\n",
            "Epoch 29/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5765 - accuracy: 0.6815 - val_loss: 0.5864 - val_accuracy: 0.6832\n",
            "Epoch 30/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5743 - accuracy: 0.6830 - val_loss: 0.5847 - val_accuracy: 0.6830\n",
            "Epoch 31/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5721 - accuracy: 0.6850 - val_loss: 0.5838 - val_accuracy: 0.6802\n",
            "Epoch 32/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5727 - accuracy: 0.6813 - val_loss: 0.5899 - val_accuracy: 0.6786\n",
            "Epoch 33/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5738 - accuracy: 0.6855 - val_loss: 0.5893 - val_accuracy: 0.6812\n",
            "Epoch 34/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5727 - accuracy: 0.6823 - val_loss: 0.5863 - val_accuracy: 0.6791\n",
            "Epoch 35/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5734 - accuracy: 0.6860 - val_loss: 0.5857 - val_accuracy: 0.6840\n",
            "Epoch 36/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5695 - accuracy: 0.6857 - val_loss: 0.5866 - val_accuracy: 0.6822\n",
            "Epoch 37/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5705 - accuracy: 0.6843 - val_loss: 0.5889 - val_accuracy: 0.6832\n",
            "Epoch 38/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5674 - accuracy: 0.6866 - val_loss: 0.5876 - val_accuracy: 0.6853\n",
            "Epoch 39/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5667 - accuracy: 0.6836 - val_loss: 0.5900 - val_accuracy: 0.6830\n",
            "Epoch 40/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5682 - accuracy: 0.6855 - val_loss: 0.5881 - val_accuracy: 0.6807\n",
            "Epoch 41/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5673 - accuracy: 0.6887 - val_loss: 0.5887 - val_accuracy: 0.6835\n",
            "Epoch 42/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5643 - accuracy: 0.6888 - val_loss: 0.5863 - val_accuracy: 0.6814\n",
            "Epoch 43/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5671 - accuracy: 0.6851 - val_loss: 0.5877 - val_accuracy: 0.6799\n",
            "Epoch 44/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5653 - accuracy: 0.6899 - val_loss: 0.5906 - val_accuracy: 0.6832\n",
            "Epoch 45/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5632 - accuracy: 0.6881 - val_loss: 0.5905 - val_accuracy: 0.6802\n",
            "Epoch 46/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5648 - accuracy: 0.6908 - val_loss: 0.5887 - val_accuracy: 0.6812\n",
            "Epoch 47/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5631 - accuracy: 0.6953 - val_loss: 0.5870 - val_accuracy: 0.6830\n",
            "Epoch 48/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5647 - accuracy: 0.6911 - val_loss: 0.5886 - val_accuracy: 0.6863\n",
            "Epoch 49/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5603 - accuracy: 0.6943 - val_loss: 0.5879 - val_accuracy: 0.6840\n",
            "Epoch 50/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5611 - accuracy: 0.6937 - val_loss: 0.5880 - val_accuracy: 0.6878\n",
            "Epoch 51/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5620 - accuracy: 0.6917 - val_loss: 0.5931 - val_accuracy: 0.6807\n",
            "Epoch 52/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5601 - accuracy: 0.6880 - val_loss: 0.5941 - val_accuracy: 0.6837\n",
            "Epoch 53/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5602 - accuracy: 0.6946 - val_loss: 0.5907 - val_accuracy: 0.6809\n",
            "Epoch 54/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5586 - accuracy: 0.6955 - val_loss: 0.5889 - val_accuracy: 0.6860\n",
            "Epoch 55/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5599 - accuracy: 0.6917 - val_loss: 0.5892 - val_accuracy: 0.6886\n",
            "Epoch 56/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5593 - accuracy: 0.6937 - val_loss: 0.5893 - val_accuracy: 0.6830\n",
            "Epoch 57/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5549 - accuracy: 0.6965 - val_loss: 0.5943 - val_accuracy: 0.6738\n",
            "Epoch 58/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5568 - accuracy: 0.6937 - val_loss: 0.5933 - val_accuracy: 0.6763\n",
            "Epoch 59/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5575 - accuracy: 0.6950 - val_loss: 0.5947 - val_accuracy: 0.6822\n",
            "Epoch 60/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5567 - accuracy: 0.6932 - val_loss: 0.5964 - val_accuracy: 0.6797\n",
            "Epoch 61/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5599 - accuracy: 0.6910 - val_loss: 0.5942 - val_accuracy: 0.6819\n",
            "Epoch 62/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5551 - accuracy: 0.6986 - val_loss: 0.5924 - val_accuracy: 0.6781\n",
            "Epoch 63/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5551 - accuracy: 0.7006 - val_loss: 0.5941 - val_accuracy: 0.6825\n",
            "Epoch 64/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5553 - accuracy: 0.6983 - val_loss: 0.5964 - val_accuracy: 0.6735\n",
            "Epoch 65/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5541 - accuracy: 0.6988 - val_loss: 0.5974 - val_accuracy: 0.6774\n",
            "Epoch 66/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5532 - accuracy: 0.7011 - val_loss: 0.5981 - val_accuracy: 0.6710\n",
            "Epoch 67/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5543 - accuracy: 0.6968 - val_loss: 0.5976 - val_accuracy: 0.6748\n",
            "Epoch 68/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5512 - accuracy: 0.6974 - val_loss: 0.5943 - val_accuracy: 0.6812\n",
            "Epoch 69/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5519 - accuracy: 0.6991 - val_loss: 0.6015 - val_accuracy: 0.6858\n",
            "Epoch 70/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5548 - accuracy: 0.6985 - val_loss: 0.6023 - val_accuracy: 0.6786\n",
            "Epoch 71/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5525 - accuracy: 0.6995 - val_loss: 0.6036 - val_accuracy: 0.6807\n",
            "Epoch 72/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5523 - accuracy: 0.6991 - val_loss: 0.5984 - val_accuracy: 0.6812\n",
            "Epoch 73/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5542 - accuracy: 0.6958 - val_loss: 0.5947 - val_accuracy: 0.6776\n",
            "Epoch 74/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5494 - accuracy: 0.7006 - val_loss: 0.6002 - val_accuracy: 0.6822\n",
            "Epoch 75/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5492 - accuracy: 0.7061 - val_loss: 0.6044 - val_accuracy: 0.6807\n",
            "Epoch 76/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5474 - accuracy: 0.7009 - val_loss: 0.6001 - val_accuracy: 0.6814\n",
            "Epoch 77/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5522 - accuracy: 0.7018 - val_loss: 0.5993 - val_accuracy: 0.6682\n",
            "Epoch 78/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5508 - accuracy: 0.7006 - val_loss: 0.6030 - val_accuracy: 0.6735\n",
            "Epoch 79/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5487 - accuracy: 0.7011 - val_loss: 0.6057 - val_accuracy: 0.6687\n",
            "Epoch 80/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5520 - accuracy: 0.6982 - val_loss: 0.6049 - val_accuracy: 0.6730\n",
            "154/154 [==============================] - 0s 1ms/step\n",
            "DNN Accuracy (AAC): 0.6691790588714606\n",
            "DNN F1 Score (AAC): 0.5588454947459104\n",
            "RandomForest Best Params: {'max_depth': 10, 'n_estimators': 100}\n",
            "RandomForest Accuracy (DPC): 0.6708087186799756\n",
            "RandomForest F1 Score (DPC): 0.4014874420872958\n",
            "KNN Best Params: {'n_neighbors': 9}\n",
            "KNN Accuracy (DPC): 0.6453452841719292\n",
            "KNN F1 Score (DPC): 0.5358864936267382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:04:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:04:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:04:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:04:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:04:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:04:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:04:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:05:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:05:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:05:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:05:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Best Params: {'max_depth': 12, 'n_estimators': 100}\n",
            "XGBoost Accuracy (DPC): 0.6622530046852719\n",
            "XGBoost F1 Score (DPC): 0.5665153318869502\n",
            "Epoch 1/80\n",
            "491/491 [==============================] - 3s 4ms/step - loss: 0.7807 - accuracy: 0.6174 - val_loss: 0.6252 - val_accuracy: 0.6751\n",
            "Epoch 2/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.6340 - accuracy: 0.6587 - val_loss: 0.6160 - val_accuracy: 0.6756\n",
            "Epoch 3/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.6105 - accuracy: 0.6634 - val_loss: 0.6094 - val_accuracy: 0.6751\n",
            "Epoch 4/80\n",
            "491/491 [==============================] - 4s 7ms/step - loss: 0.5969 - accuracy: 0.6710 - val_loss: 0.6053 - val_accuracy: 0.6763\n",
            "Epoch 5/80\n",
            "491/491 [==============================] - 4s 7ms/step - loss: 0.5825 - accuracy: 0.6813 - val_loss: 0.5983 - val_accuracy: 0.6763\n",
            "Epoch 6/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5697 - accuracy: 0.6901 - val_loss: 0.6012 - val_accuracy: 0.6766\n",
            "Epoch 7/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5519 - accuracy: 0.7037 - val_loss: 0.6025 - val_accuracy: 0.6715\n",
            "Epoch 8/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5287 - accuracy: 0.7187 - val_loss: 0.6098 - val_accuracy: 0.6710\n",
            "Epoch 9/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5028 - accuracy: 0.7437 - val_loss: 0.6104 - val_accuracy: 0.6766\n",
            "Epoch 10/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.4792 - accuracy: 0.7646 - val_loss: 0.6265 - val_accuracy: 0.6674\n",
            "Epoch 11/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.4498 - accuracy: 0.7829 - val_loss: 0.6326 - val_accuracy: 0.6603\n",
            "Epoch 12/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.4182 - accuracy: 0.8053 - val_loss: 0.6536 - val_accuracy: 0.6662\n",
            "Epoch 13/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.3970 - accuracy: 0.8202 - val_loss: 0.6882 - val_accuracy: 0.6608\n",
            "Epoch 14/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.3645 - accuracy: 0.8337 - val_loss: 0.7051 - val_accuracy: 0.6550\n",
            "Epoch 15/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.3383 - accuracy: 0.8494 - val_loss: 0.7275 - val_accuracy: 0.6486\n",
            "Epoch 16/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.3254 - accuracy: 0.8602 - val_loss: 0.7524 - val_accuracy: 0.6560\n",
            "Epoch 17/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.3008 - accuracy: 0.8711 - val_loss: 0.7883 - val_accuracy: 0.6600\n",
            "Epoch 18/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.2982 - accuracy: 0.8746 - val_loss: 0.8244 - val_accuracy: 0.6590\n",
            "Epoch 19/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2775 - accuracy: 0.8818 - val_loss: 0.8111 - val_accuracy: 0.6552\n",
            "Epoch 20/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2602 - accuracy: 0.8875 - val_loss: 0.8755 - val_accuracy: 0.6590\n",
            "Epoch 21/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2489 - accuracy: 0.8942 - val_loss: 0.9080 - val_accuracy: 0.6631\n",
            "Epoch 22/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2408 - accuracy: 0.8997 - val_loss: 0.9227 - val_accuracy: 0.6575\n",
            "Epoch 23/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2408 - accuracy: 0.9002 - val_loss: 0.8848 - val_accuracy: 0.6544\n",
            "Epoch 24/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2218 - accuracy: 0.9069 - val_loss: 0.9581 - val_accuracy: 0.6567\n",
            "Epoch 25/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.2203 - accuracy: 0.9065 - val_loss: 0.9934 - val_accuracy: 0.6600\n",
            "Epoch 26/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.2133 - accuracy: 0.9081 - val_loss: 0.9992 - val_accuracy: 0.6593\n",
            "Epoch 27/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2033 - accuracy: 0.9144 - val_loss: 1.0807 - val_accuracy: 0.6595\n",
            "Epoch 28/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1969 - accuracy: 0.9176 - val_loss: 1.1242 - val_accuracy: 0.6628\n",
            "Epoch 29/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1916 - accuracy: 0.9214 - val_loss: 1.0831 - val_accuracy: 0.6618\n",
            "Epoch 30/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1881 - accuracy: 0.9207 - val_loss: 1.0681 - val_accuracy: 0.6552\n",
            "Epoch 31/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1927 - accuracy: 0.9185 - val_loss: 1.0349 - val_accuracy: 0.6527\n",
            "Epoch 32/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1853 - accuracy: 0.9205 - val_loss: 1.1290 - val_accuracy: 0.6567\n",
            "Epoch 33/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1811 - accuracy: 0.9240 - val_loss: 1.1486 - val_accuracy: 0.6641\n",
            "Epoch 34/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1758 - accuracy: 0.9279 - val_loss: 1.1098 - val_accuracy: 0.6488\n",
            "Epoch 35/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1710 - accuracy: 0.9290 - val_loss: 1.1712 - val_accuracy: 0.6570\n",
            "Epoch 36/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1661 - accuracy: 0.9303 - val_loss: 1.2712 - val_accuracy: 0.6626\n",
            "Epoch 37/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1648 - accuracy: 0.9297 - val_loss: 1.1637 - val_accuracy: 0.6598\n",
            "Epoch 38/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1658 - accuracy: 0.9307 - val_loss: 1.1791 - val_accuracy: 0.6572\n",
            "Epoch 39/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1649 - accuracy: 0.9290 - val_loss: 1.2268 - val_accuracy: 0.6713\n",
            "Epoch 40/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1593 - accuracy: 0.9323 - val_loss: 1.2499 - val_accuracy: 0.6667\n",
            "Epoch 41/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.1544 - accuracy: 0.9351 - val_loss: 1.3094 - val_accuracy: 0.6656\n",
            "Epoch 42/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1582 - accuracy: 0.9326 - val_loss: 1.2597 - val_accuracy: 0.6634\n",
            "Epoch 43/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1521 - accuracy: 0.9359 - val_loss: 1.3136 - val_accuracy: 0.6656\n",
            "Epoch 44/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1450 - accuracy: 0.9389 - val_loss: 1.3639 - val_accuracy: 0.6606\n",
            "Epoch 45/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1481 - accuracy: 0.9373 - val_loss: 1.3178 - val_accuracy: 0.6667\n",
            "Epoch 46/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1461 - accuracy: 0.9387 - val_loss: 1.3725 - val_accuracy: 0.6616\n",
            "Epoch 47/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1448 - accuracy: 0.9368 - val_loss: 1.3801 - val_accuracy: 0.6659\n",
            "Epoch 48/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1389 - accuracy: 0.9411 - val_loss: 1.4305 - val_accuracy: 0.6639\n",
            "Epoch 49/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1432 - accuracy: 0.9398 - val_loss: 1.4404 - val_accuracy: 0.6679\n",
            "Epoch 50/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1451 - accuracy: 0.9378 - val_loss: 1.3656 - val_accuracy: 0.6588\n",
            "Epoch 51/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1384 - accuracy: 0.9427 - val_loss: 1.4496 - val_accuracy: 0.6608\n",
            "Epoch 52/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.9414 - val_loss: 1.3889 - val_accuracy: 0.6616\n",
            "Epoch 53/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.1372 - accuracy: 0.9427 - val_loss: 1.5035 - val_accuracy: 0.6659\n",
            "Epoch 54/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1356 - accuracy: 0.9450 - val_loss: 1.5029 - val_accuracy: 0.6646\n",
            "Epoch 55/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.1386 - accuracy: 0.9414 - val_loss: 1.4438 - val_accuracy: 0.6677\n",
            "Epoch 56/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1313 - accuracy: 0.9465 - val_loss: 1.5415 - val_accuracy: 0.6695\n",
            "Epoch 57/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1280 - accuracy: 0.9479 - val_loss: 1.5323 - val_accuracy: 0.6677\n",
            "Epoch 58/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1263 - accuracy: 0.9464 - val_loss: 1.5417 - val_accuracy: 0.6695\n",
            "Epoch 59/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1241 - accuracy: 0.9492 - val_loss: 1.5084 - val_accuracy: 0.6664\n",
            "Epoch 60/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1320 - accuracy: 0.9455 - val_loss: 1.3604 - val_accuracy: 0.6651\n",
            "Epoch 61/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.1238 - accuracy: 0.9467 - val_loss: 1.5955 - val_accuracy: 0.6654\n",
            "Epoch 62/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.1197 - accuracy: 0.9501 - val_loss: 1.6706 - val_accuracy: 0.6664\n",
            "Epoch 63/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1229 - accuracy: 0.9500 - val_loss: 1.5502 - val_accuracy: 0.6644\n",
            "Epoch 64/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1254 - accuracy: 0.9478 - val_loss: 1.4510 - val_accuracy: 0.6705\n",
            "Epoch 65/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1219 - accuracy: 0.9488 - val_loss: 1.4920 - val_accuracy: 0.6621\n",
            "Epoch 66/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1263 - accuracy: 0.9465 - val_loss: 1.6800 - val_accuracy: 0.6634\n",
            "Epoch 67/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.1204 - accuracy: 0.9491 - val_loss: 1.7148 - val_accuracy: 0.6628\n",
            "Epoch 68/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.1192 - accuracy: 0.9504 - val_loss: 1.6179 - val_accuracy: 0.6598\n",
            "Epoch 69/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1256 - accuracy: 0.9480 - val_loss: 1.5754 - val_accuracy: 0.6611\n",
            "Epoch 70/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.1197 - accuracy: 0.9501 - val_loss: 1.7353 - val_accuracy: 0.6644\n",
            "Epoch 71/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.1151 - accuracy: 0.9513 - val_loss: 1.7195 - val_accuracy: 0.6606\n",
            "Epoch 72/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1179 - accuracy: 0.9482 - val_loss: 1.7543 - val_accuracy: 0.6611\n",
            "Epoch 73/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.1125 - accuracy: 0.9542 - val_loss: 1.6852 - val_accuracy: 0.6656\n",
            "Epoch 74/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1205 - accuracy: 0.9514 - val_loss: 1.8108 - val_accuracy: 0.6649\n",
            "Epoch 75/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.1186 - accuracy: 0.9510 - val_loss: 1.5793 - val_accuracy: 0.6616\n",
            "Epoch 76/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1111 - accuracy: 0.9555 - val_loss: 1.7756 - val_accuracy: 0.6700\n",
            "Epoch 77/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1087 - accuracy: 0.9543 - val_loss: 1.7953 - val_accuracy: 0.6634\n",
            "Epoch 78/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1096 - accuracy: 0.9569 - val_loss: 1.6976 - val_accuracy: 0.6649\n",
            "Epoch 79/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1069 - accuracy: 0.9550 - val_loss: 1.8995 - val_accuracy: 0.6672\n",
            "Epoch 80/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1159 - accuracy: 0.9517 - val_loss: 1.8023 - val_accuracy: 0.6595\n",
            "154/154 [==============================] - 0s 2ms/step\n",
            "DNN Accuracy (DPC): 0.6488083112650235\n",
            "DNN F1 Score (DPC): 0.5736585768864959\n",
            "RandomForest Best Params: {'max_depth': 12, 'n_estimators': 100}\n",
            "RandomForest Accuracy (One-Hot): 0.6756976981055205\n",
            "RandomForest F1 Score (One-Hot): 0.4728859396465298\n",
            "KNN Best Params: {'n_neighbors': 9}\n",
            "KNN Accuracy (One-Hot): 0.6341413729883887\n",
            "KNN F1 Score (One-Hot): 0.5443692688049347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:08:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:08:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:08:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:08:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:08:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:08:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:08:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:08:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:08:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:08:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:08:53] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Best Params: {'max_depth': 10, 'n_estimators': 100}\n",
            "XGBoost Accuracy (One-Hot): 0.6549195355469546\n",
            "XGBoost F1 Score (One-Hot): 0.5755305252085227\n",
            "Epoch 1/80\n",
            "491/491 [==============================] - 3s 3ms/step - loss: 0.6625 - accuracy: 0.6328 - val_loss: 0.6052 - val_accuracy: 0.6751\n",
            "Epoch 2/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.6181 - accuracy: 0.6616 - val_loss: 0.6018 - val_accuracy: 0.6746\n",
            "Epoch 3/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.6091 - accuracy: 0.6648 - val_loss: 0.5950 - val_accuracy: 0.6748\n",
            "Epoch 4/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.6023 - accuracy: 0.6650 - val_loss: 0.5914 - val_accuracy: 0.6784\n",
            "Epoch 5/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5972 - accuracy: 0.6701 - val_loss: 0.5886 - val_accuracy: 0.6763\n",
            "Epoch 6/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5934 - accuracy: 0.6739 - val_loss: 0.5854 - val_accuracy: 0.6832\n",
            "Epoch 7/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5901 - accuracy: 0.6696 - val_loss: 0.5839 - val_accuracy: 0.6883\n",
            "Epoch 8/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5857 - accuracy: 0.6738 - val_loss: 0.5845 - val_accuracy: 0.6840\n",
            "Epoch 9/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5837 - accuracy: 0.6750 - val_loss: 0.5845 - val_accuracy: 0.6931\n",
            "Epoch 10/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5856 - accuracy: 0.6761 - val_loss: 0.5818 - val_accuracy: 0.6878\n",
            "Epoch 11/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5846 - accuracy: 0.6755 - val_loss: 0.5836 - val_accuracy: 0.6819\n",
            "Epoch 12/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5816 - accuracy: 0.6766 - val_loss: 0.5819 - val_accuracy: 0.6865\n",
            "Epoch 13/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5840 - accuracy: 0.6797 - val_loss: 0.5819 - val_accuracy: 0.6883\n",
            "Epoch 14/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5782 - accuracy: 0.6836 - val_loss: 0.5825 - val_accuracy: 0.6845\n",
            "Epoch 15/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5796 - accuracy: 0.6836 - val_loss: 0.5838 - val_accuracy: 0.6827\n",
            "Epoch 16/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5771 - accuracy: 0.6840 - val_loss: 0.5828 - val_accuracy: 0.6847\n",
            "Epoch 17/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5753 - accuracy: 0.6855 - val_loss: 0.5825 - val_accuracy: 0.6842\n",
            "Epoch 18/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5795 - accuracy: 0.6817 - val_loss: 0.5815 - val_accuracy: 0.6873\n",
            "Epoch 19/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5738 - accuracy: 0.6878 - val_loss: 0.5813 - val_accuracy: 0.6860\n",
            "Epoch 20/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5757 - accuracy: 0.6883 - val_loss: 0.5838 - val_accuracy: 0.6814\n",
            "Epoch 21/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5739 - accuracy: 0.6890 - val_loss: 0.5830 - val_accuracy: 0.6804\n",
            "Epoch 22/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.5720 - accuracy: 0.6866 - val_loss: 0.5856 - val_accuracy: 0.6850\n",
            "Epoch 23/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5727 - accuracy: 0.6868 - val_loss: 0.5836 - val_accuracy: 0.6830\n",
            "Epoch 24/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5714 - accuracy: 0.6893 - val_loss: 0.5832 - val_accuracy: 0.6791\n",
            "Epoch 25/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5666 - accuracy: 0.6951 - val_loss: 0.5839 - val_accuracy: 0.6830\n",
            "Epoch 26/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5703 - accuracy: 0.6907 - val_loss: 0.5837 - val_accuracy: 0.6807\n",
            "Epoch 27/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5694 - accuracy: 0.6927 - val_loss: 0.5831 - val_accuracy: 0.6883\n",
            "Epoch 28/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5696 - accuracy: 0.6898 - val_loss: 0.5836 - val_accuracy: 0.6825\n",
            "Epoch 29/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5670 - accuracy: 0.6901 - val_loss: 0.5856 - val_accuracy: 0.6784\n",
            "Epoch 30/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.6906 - val_loss: 0.5841 - val_accuracy: 0.6791\n",
            "Epoch 31/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5639 - accuracy: 0.6960 - val_loss: 0.5845 - val_accuracy: 0.6802\n",
            "Epoch 32/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5657 - accuracy: 0.6934 - val_loss: 0.5858 - val_accuracy: 0.6758\n",
            "Epoch 33/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5671 - accuracy: 0.6908 - val_loss: 0.5873 - val_accuracy: 0.6822\n",
            "Epoch 34/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5642 - accuracy: 0.6971 - val_loss: 0.5840 - val_accuracy: 0.6832\n",
            "Epoch 35/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5655 - accuracy: 0.6943 - val_loss: 0.5849 - val_accuracy: 0.6827\n",
            "Epoch 36/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5642 - accuracy: 0.6971 - val_loss: 0.5855 - val_accuracy: 0.6748\n",
            "Epoch 37/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5628 - accuracy: 0.6950 - val_loss: 0.5849 - val_accuracy: 0.6746\n",
            "Epoch 38/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5616 - accuracy: 0.6918 - val_loss: 0.5843 - val_accuracy: 0.6814\n",
            "Epoch 39/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5587 - accuracy: 0.7016 - val_loss: 0.5855 - val_accuracy: 0.6850\n",
            "Epoch 40/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5638 - accuracy: 0.6955 - val_loss: 0.5837 - val_accuracy: 0.6789\n",
            "Epoch 41/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5624 - accuracy: 0.6929 - val_loss: 0.5864 - val_accuracy: 0.6804\n",
            "Epoch 42/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5613 - accuracy: 0.6959 - val_loss: 0.5854 - val_accuracy: 0.6812\n",
            "Epoch 43/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5604 - accuracy: 0.6963 - val_loss: 0.5867 - val_accuracy: 0.6743\n",
            "Epoch 44/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5612 - accuracy: 0.6988 - val_loss: 0.5874 - val_accuracy: 0.6776\n",
            "Epoch 45/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5585 - accuracy: 0.6982 - val_loss: 0.5871 - val_accuracy: 0.6769\n",
            "Epoch 46/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5571 - accuracy: 0.7020 - val_loss: 0.5886 - val_accuracy: 0.6776\n",
            "Epoch 47/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5602 - accuracy: 0.7022 - val_loss: 0.5853 - val_accuracy: 0.6809\n",
            "Epoch 48/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5571 - accuracy: 0.7022 - val_loss: 0.5892 - val_accuracy: 0.6741\n",
            "Epoch 49/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5585 - accuracy: 0.7019 - val_loss: 0.5884 - val_accuracy: 0.6771\n",
            "Epoch 50/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5570 - accuracy: 0.6977 - val_loss: 0.5894 - val_accuracy: 0.6728\n",
            "Epoch 51/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5554 - accuracy: 0.7024 - val_loss: 0.5872 - val_accuracy: 0.6809\n",
            "Epoch 52/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5521 - accuracy: 0.7052 - val_loss: 0.5900 - val_accuracy: 0.6807\n",
            "Epoch 53/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5549 - accuracy: 0.7036 - val_loss: 0.5909 - val_accuracy: 0.6774\n",
            "Epoch 54/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5546 - accuracy: 0.7028 - val_loss: 0.5895 - val_accuracy: 0.6771\n",
            "Epoch 55/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5544 - accuracy: 0.7010 - val_loss: 0.5906 - val_accuracy: 0.6779\n",
            "Epoch 56/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5525 - accuracy: 0.7025 - val_loss: 0.5958 - val_accuracy: 0.6779\n",
            "Epoch 57/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5551 - accuracy: 0.7024 - val_loss: 0.5931 - val_accuracy: 0.6738\n",
            "Epoch 58/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5537 - accuracy: 0.7058 - val_loss: 0.5911 - val_accuracy: 0.6835\n",
            "Epoch 59/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5534 - accuracy: 0.7029 - val_loss: 0.5924 - val_accuracy: 0.6756\n",
            "Epoch 60/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5541 - accuracy: 0.7022 - val_loss: 0.5920 - val_accuracy: 0.6718\n",
            "Epoch 61/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5529 - accuracy: 0.7012 - val_loss: 0.5940 - val_accuracy: 0.6753\n",
            "Epoch 62/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5481 - accuracy: 0.7047 - val_loss: 0.5884 - val_accuracy: 0.6769\n",
            "Epoch 63/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5524 - accuracy: 0.7034 - val_loss: 0.5911 - val_accuracy: 0.6845\n",
            "Epoch 64/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5537 - accuracy: 0.7015 - val_loss: 0.5915 - val_accuracy: 0.6786\n",
            "Epoch 65/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5507 - accuracy: 0.7060 - val_loss: 0.5920 - val_accuracy: 0.6756\n",
            "Epoch 66/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5503 - accuracy: 0.7065 - val_loss: 0.5907 - val_accuracy: 0.6746\n",
            "Epoch 67/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5469 - accuracy: 0.7102 - val_loss: 0.5919 - val_accuracy: 0.6794\n",
            "Epoch 68/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5495 - accuracy: 0.7036 - val_loss: 0.5959 - val_accuracy: 0.6710\n",
            "Epoch 69/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5495 - accuracy: 0.7074 - val_loss: 0.5948 - val_accuracy: 0.6769\n",
            "Epoch 70/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5493 - accuracy: 0.7065 - val_loss: 0.5921 - val_accuracy: 0.6776\n",
            "Epoch 71/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5505 - accuracy: 0.7068 - val_loss: 0.5962 - val_accuracy: 0.6730\n",
            "Epoch 72/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5501 - accuracy: 0.7092 - val_loss: 0.5931 - val_accuracy: 0.6774\n",
            "Epoch 73/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.5474 - accuracy: 0.7088 - val_loss: 0.5995 - val_accuracy: 0.6751\n",
            "Epoch 74/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5486 - accuracy: 0.7072 - val_loss: 0.5909 - val_accuracy: 0.6718\n",
            "Epoch 75/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5459 - accuracy: 0.7085 - val_loss: 0.5914 - val_accuracy: 0.6718\n",
            "Epoch 76/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5459 - accuracy: 0.7097 - val_loss: 0.5963 - val_accuracy: 0.6756\n",
            "Epoch 77/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5467 - accuracy: 0.7079 - val_loss: 0.5965 - val_accuracy: 0.6769\n",
            "Epoch 78/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5492 - accuracy: 0.7065 - val_loss: 0.5940 - val_accuracy: 0.6725\n",
            "Epoch 79/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5456 - accuracy: 0.7097 - val_loss: 0.5940 - val_accuracy: 0.6769\n",
            "Epoch 80/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5447 - accuracy: 0.7062 - val_loss: 0.5956 - val_accuracy: 0.6771\n",
            "154/154 [==============================] - 0s 2ms/step\n",
            "DNN Accuracy (One-Hot): 0.6759014055815848\n",
            "DNN F1 Score (One-Hot): 0.5643569774138535\n",
            "RandomForest Best Params: {'max_depth': 10, 'n_estimators': 100}\n",
            "RandomForest Accuracy (TF-IDF): 0.6777347728661642\n",
            "RandomForest F1 Score (TF-IDF): 0.4687360275385756\n",
            "KNN Best Params: {'n_neighbors': 9}\n",
            "KNN Accuracy (TF-IDF): 0.6439193318394785\n",
            "KNN F1 Score (TF-IDF): 0.5476114157402319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:12:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:12:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:12:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:12:30] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:12:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:12:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:12:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:12:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:12:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:12:53] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:12:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Best Params: {'max_depth': 12, 'n_estimators': 100}\n",
            "XGBoost Accuracy (TF-IDF): 0.6553269504990833\n",
            "XGBoost F1 Score (TF-IDF): 0.573802258050215\n",
            "Epoch 1/80\n",
            "491/491 [==============================] - 3s 4ms/step - loss: 0.6276 - accuracy: 0.6640 - val_loss: 0.6038 - val_accuracy: 0.6771\n",
            "Epoch 2/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.6104 - accuracy: 0.6618 - val_loss: 0.5951 - val_accuracy: 0.6784\n",
            "Epoch 3/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5998 - accuracy: 0.6678 - val_loss: 0.5912 - val_accuracy: 0.6771\n",
            "Epoch 4/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5971 - accuracy: 0.6650 - val_loss: 0.5872 - val_accuracy: 0.6804\n",
            "Epoch 5/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5910 - accuracy: 0.6723 - val_loss: 0.5867 - val_accuracy: 0.6822\n",
            "Epoch 6/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5889 - accuracy: 0.6752 - val_loss: 0.5852 - val_accuracy: 0.6812\n",
            "Epoch 7/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5885 - accuracy: 0.6735 - val_loss: 0.5877 - val_accuracy: 0.6789\n",
            "Epoch 8/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5848 - accuracy: 0.6788 - val_loss: 0.5859 - val_accuracy: 0.6853\n",
            "Epoch 9/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5825 - accuracy: 0.6784 - val_loss: 0.5864 - val_accuracy: 0.6779\n",
            "Epoch 10/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5802 - accuracy: 0.6817 - val_loss: 0.5865 - val_accuracy: 0.6845\n",
            "Epoch 11/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5789 - accuracy: 0.6792 - val_loss: 0.5857 - val_accuracy: 0.6868\n",
            "Epoch 12/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5799 - accuracy: 0.6823 - val_loss: 0.5857 - val_accuracy: 0.6822\n",
            "Epoch 13/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5762 - accuracy: 0.6836 - val_loss: 0.5843 - val_accuracy: 0.6830\n",
            "Epoch 14/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5763 - accuracy: 0.6857 - val_loss: 0.5844 - val_accuracy: 0.6850\n",
            "Epoch 15/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5750 - accuracy: 0.6867 - val_loss: 0.5871 - val_accuracy: 0.6746\n",
            "Epoch 16/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5728 - accuracy: 0.6887 - val_loss: 0.5834 - val_accuracy: 0.6832\n",
            "Epoch 17/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5723 - accuracy: 0.6860 - val_loss: 0.5844 - val_accuracy: 0.6837\n",
            "Epoch 18/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5744 - accuracy: 0.6880 - val_loss: 0.5837 - val_accuracy: 0.6835\n",
            "Epoch 19/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5728 - accuracy: 0.6878 - val_loss: 0.5837 - val_accuracy: 0.6766\n",
            "Epoch 20/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5730 - accuracy: 0.6902 - val_loss: 0.5828 - val_accuracy: 0.6837\n",
            "Epoch 21/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5720 - accuracy: 0.6901 - val_loss: 0.5880 - val_accuracy: 0.6842\n",
            "Epoch 22/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5707 - accuracy: 0.6894 - val_loss: 0.5858 - val_accuracy: 0.6837\n",
            "Epoch 23/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5694 - accuracy: 0.6905 - val_loss: 0.5832 - val_accuracy: 0.6799\n",
            "Epoch 24/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5699 - accuracy: 0.6927 - val_loss: 0.5836 - val_accuracy: 0.6873\n",
            "Epoch 25/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5712 - accuracy: 0.6852 - val_loss: 0.5844 - val_accuracy: 0.6794\n",
            "Epoch 26/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.6980 - val_loss: 0.5850 - val_accuracy: 0.6809\n",
            "Epoch 27/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5693 - accuracy: 0.6927 - val_loss: 0.5822 - val_accuracy: 0.6853\n",
            "Epoch 28/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.6889 - val_loss: 0.5855 - val_accuracy: 0.6789\n",
            "Epoch 29/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.5684 - accuracy: 0.6937 - val_loss: 0.5836 - val_accuracy: 0.6807\n",
            "Epoch 30/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5646 - accuracy: 0.6965 - val_loss: 0.5854 - val_accuracy: 0.6692\n",
            "Epoch 31/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5656 - accuracy: 0.6932 - val_loss: 0.5867 - val_accuracy: 0.6784\n",
            "Epoch 32/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.6918 - val_loss: 0.5849 - val_accuracy: 0.6784\n",
            "Epoch 33/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5659 - accuracy: 0.6923 - val_loss: 0.5836 - val_accuracy: 0.6825\n",
            "Epoch 34/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5658 - accuracy: 0.6960 - val_loss: 0.5846 - val_accuracy: 0.6799\n",
            "Epoch 35/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5648 - accuracy: 0.6955 - val_loss: 0.5852 - val_accuracy: 0.6769\n",
            "Epoch 36/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5628 - accuracy: 0.6970 - val_loss: 0.5844 - val_accuracy: 0.6769\n",
            "Epoch 37/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.6915 - val_loss: 0.5853 - val_accuracy: 0.6774\n",
            "Epoch 38/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5638 - accuracy: 0.6953 - val_loss: 0.5851 - val_accuracy: 0.6797\n",
            "Epoch 39/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5641 - accuracy: 0.6957 - val_loss: 0.5837 - val_accuracy: 0.6822\n",
            "Epoch 40/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5612 - accuracy: 0.6937 - val_loss: 0.5861 - val_accuracy: 0.6845\n",
            "Epoch 41/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5610 - accuracy: 0.6965 - val_loss: 0.5873 - val_accuracy: 0.6766\n",
            "Epoch 42/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5616 - accuracy: 0.6985 - val_loss: 0.5878 - val_accuracy: 0.6758\n",
            "Epoch 43/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5582 - accuracy: 0.6968 - val_loss: 0.5860 - val_accuracy: 0.6825\n",
            "Epoch 44/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5601 - accuracy: 0.6981 - val_loss: 0.5871 - val_accuracy: 0.6837\n",
            "Epoch 45/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5592 - accuracy: 0.6991 - val_loss: 0.5907 - val_accuracy: 0.6791\n",
            "Epoch 46/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5578 - accuracy: 0.7022 - val_loss: 0.5891 - val_accuracy: 0.6753\n",
            "Epoch 47/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5595 - accuracy: 0.7016 - val_loss: 0.5878 - val_accuracy: 0.6758\n",
            "Epoch 48/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5610 - accuracy: 0.6968 - val_loss: 0.5868 - val_accuracy: 0.6822\n",
            "Epoch 49/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.5571 - accuracy: 0.7036 - val_loss: 0.5914 - val_accuracy: 0.6822\n",
            "Epoch 50/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.5558 - accuracy: 0.7041 - val_loss: 0.5876 - val_accuracy: 0.6771\n",
            "Epoch 51/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5582 - accuracy: 0.7037 - val_loss: 0.5894 - val_accuracy: 0.6830\n",
            "Epoch 52/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5566 - accuracy: 0.7008 - val_loss: 0.5885 - val_accuracy: 0.6746\n",
            "Epoch 53/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5563 - accuracy: 0.7054 - val_loss: 0.5906 - val_accuracy: 0.6830\n",
            "Epoch 54/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5550 - accuracy: 0.7017 - val_loss: 0.5916 - val_accuracy: 0.6763\n",
            "Epoch 55/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5568 - accuracy: 0.7039 - val_loss: 0.5876 - val_accuracy: 0.6794\n",
            "Epoch 56/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5556 - accuracy: 0.7031 - val_loss: 0.5889 - val_accuracy: 0.6779\n",
            "Epoch 57/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5544 - accuracy: 0.7034 - val_loss: 0.5908 - val_accuracy: 0.6835\n",
            "Epoch 58/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5561 - accuracy: 0.7011 - val_loss: 0.5874 - val_accuracy: 0.6761\n",
            "Epoch 59/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5542 - accuracy: 0.7052 - val_loss: 0.5926 - val_accuracy: 0.6748\n",
            "Epoch 60/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5506 - accuracy: 0.7089 - val_loss: 0.5911 - val_accuracy: 0.6723\n",
            "Epoch 61/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5546 - accuracy: 0.7029 - val_loss: 0.5922 - val_accuracy: 0.6812\n",
            "Epoch 62/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5554 - accuracy: 0.7032 - val_loss: 0.5889 - val_accuracy: 0.6735\n",
            "Epoch 63/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5520 - accuracy: 0.7072 - val_loss: 0.5915 - val_accuracy: 0.6779\n",
            "Epoch 64/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5524 - accuracy: 0.7057 - val_loss: 0.5899 - val_accuracy: 0.6700\n",
            "Epoch 65/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5545 - accuracy: 0.7036 - val_loss: 0.5894 - val_accuracy: 0.6794\n",
            "Epoch 66/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5520 - accuracy: 0.7080 - val_loss: 0.5905 - val_accuracy: 0.6835\n",
            "Epoch 67/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.5520 - accuracy: 0.7024 - val_loss: 0.5914 - val_accuracy: 0.6779\n",
            "Epoch 68/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5542 - accuracy: 0.7043 - val_loss: 0.5930 - val_accuracy: 0.6718\n",
            "Epoch 69/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5515 - accuracy: 0.7055 - val_loss: 0.5931 - val_accuracy: 0.6802\n",
            "Epoch 70/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5495 - accuracy: 0.7104 - val_loss: 0.5905 - val_accuracy: 0.6853\n",
            "Epoch 71/80\n",
            "491/491 [==============================] - 1s 3ms/step - loss: 0.5513 - accuracy: 0.7062 - val_loss: 0.5928 - val_accuracy: 0.6779\n",
            "Epoch 72/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5494 - accuracy: 0.7092 - val_loss: 0.5889 - val_accuracy: 0.6802\n",
            "Epoch 73/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5495 - accuracy: 0.7095 - val_loss: 0.5955 - val_accuracy: 0.6847\n",
            "Epoch 74/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5493 - accuracy: 0.7064 - val_loss: 0.5908 - val_accuracy: 0.6784\n",
            "Epoch 75/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.5516 - accuracy: 0.7074 - val_loss: 0.5935 - val_accuracy: 0.6690\n",
            "Epoch 76/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5488 - accuracy: 0.7099 - val_loss: 0.5940 - val_accuracy: 0.6723\n",
            "Epoch 77/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5511 - accuracy: 0.7112 - val_loss: 0.5920 - val_accuracy: 0.6802\n",
            "Epoch 78/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5498 - accuracy: 0.7097 - val_loss: 0.5910 - val_accuracy: 0.6822\n",
            "Epoch 79/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5488 - accuracy: 0.7079 - val_loss: 0.5936 - val_accuracy: 0.6718\n",
            "Epoch 80/80\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 0.5480 - accuracy: 0.7070 - val_loss: 0.5943 - val_accuracy: 0.6804\n",
            "154/154 [==============================] - 0s 3ms/step\n",
            "DNN Accuracy (TF-IDF): 0.668364228967203\n",
            "DNN F1 Score (TF-IDF): 0.5713918267755926\n",
            "RandomForest Best Params: {'max_depth': 10, 'n_estimators': 100}\n",
            "RandomForest Accuracy (Bag of Words): 0.6708087186799756\n",
            "RandomForest F1 Score (Bag of Words): 0.4014874420872958\n",
            "KNN Best Params: {'n_neighbors': 9}\n",
            "KNN Accuracy (Bag of Words): 0.641474842126706\n",
            "KNN F1 Score (Bag of Words): 0.5319102273874862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:17:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:17:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:17:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:17:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:17:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:17:31] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:17:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:17:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:17:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:17:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [09:17:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Best Params: {'max_depth': 12, 'n_estimators': 100}\n",
            "XGBoost Accuracy (Bag of Words): 0.6622530046852719\n",
            "XGBoost F1 Score (Bag of Words): 0.5665153318869502\n",
            "Epoch 1/80\n",
            "491/491 [==============================] - 4s 6ms/step - loss: 0.6370 - accuracy: 0.6561 - val_loss: 0.6111 - val_accuracy: 0.6751\n",
            "Epoch 2/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.6077 - accuracy: 0.6650 - val_loss: 0.5990 - val_accuracy: 0.6781\n",
            "Epoch 3/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5901 - accuracy: 0.6769 - val_loss: 0.5977 - val_accuracy: 0.6761\n",
            "Epoch 4/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5709 - accuracy: 0.6912 - val_loss: 0.5971 - val_accuracy: 0.6789\n",
            "Epoch 5/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5540 - accuracy: 0.7128 - val_loss: 0.5993 - val_accuracy: 0.6771\n",
            "Epoch 6/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.5281 - accuracy: 0.7321 - val_loss: 0.6042 - val_accuracy: 0.6646\n",
            "Epoch 7/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.5006 - accuracy: 0.7507 - val_loss: 0.6128 - val_accuracy: 0.6634\n",
            "Epoch 8/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.4655 - accuracy: 0.7741 - val_loss: 0.6253 - val_accuracy: 0.6606\n",
            "Epoch 9/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.4294 - accuracy: 0.8063 - val_loss: 0.6556 - val_accuracy: 0.6504\n",
            "Epoch 10/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.4011 - accuracy: 0.8194 - val_loss: 0.6848 - val_accuracy: 0.6575\n",
            "Epoch 11/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.3736 - accuracy: 0.8343 - val_loss: 0.6920 - val_accuracy: 0.6509\n",
            "Epoch 12/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.3468 - accuracy: 0.8469 - val_loss: 0.7287 - val_accuracy: 0.6542\n",
            "Epoch 13/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.3278 - accuracy: 0.8588 - val_loss: 0.7480 - val_accuracy: 0.6600\n",
            "Epoch 14/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.3060 - accuracy: 0.8689 - val_loss: 0.7743 - val_accuracy: 0.6471\n",
            "Epoch 15/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2883 - accuracy: 0.8758 - val_loss: 0.8122 - val_accuracy: 0.6565\n",
            "Epoch 16/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2702 - accuracy: 0.8883 - val_loss: 0.8672 - val_accuracy: 0.6608\n",
            "Epoch 17/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2591 - accuracy: 0.8904 - val_loss: 0.8779 - val_accuracy: 0.6557\n",
            "Epoch 18/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2419 - accuracy: 0.8991 - val_loss: 0.9406 - val_accuracy: 0.6600\n",
            "Epoch 19/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2422 - accuracy: 0.8988 - val_loss: 0.9389 - val_accuracy: 0.6516\n",
            "Epoch 20/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2407 - accuracy: 0.9018 - val_loss: 0.9399 - val_accuracy: 0.6529\n",
            "Epoch 21/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.2269 - accuracy: 0.9066 - val_loss: 0.9530 - val_accuracy: 0.6567\n",
            "Epoch 22/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2111 - accuracy: 0.9145 - val_loss: 0.9529 - val_accuracy: 0.6570\n",
            "Epoch 23/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2092 - accuracy: 0.9146 - val_loss: 0.9972 - val_accuracy: 0.6544\n",
            "Epoch 24/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.2027 - accuracy: 0.9188 - val_loss: 1.0085 - val_accuracy: 0.6516\n",
            "Epoch 25/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1998 - accuracy: 0.9208 - val_loss: 1.0449 - val_accuracy: 0.6511\n",
            "Epoch 26/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1889 - accuracy: 0.9231 - val_loss: 1.0727 - val_accuracy: 0.6608\n",
            "Epoch 27/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1901 - accuracy: 0.9242 - val_loss: 1.0823 - val_accuracy: 0.6606\n",
            "Epoch 28/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.1823 - accuracy: 0.9265 - val_loss: 1.1042 - val_accuracy: 0.6656\n",
            "Epoch 29/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.1772 - accuracy: 0.9290 - val_loss: 1.1046 - val_accuracy: 0.6646\n",
            "Epoch 30/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1711 - accuracy: 0.9335 - val_loss: 1.1254 - val_accuracy: 0.6654\n",
            "Epoch 31/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.1763 - accuracy: 0.9313 - val_loss: 1.1504 - val_accuracy: 0.6593\n",
            "Epoch 32/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1681 - accuracy: 0.9349 - val_loss: 1.1878 - val_accuracy: 0.6616\n",
            "Epoch 33/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1709 - accuracy: 0.9319 - val_loss: 1.1677 - val_accuracy: 0.6649\n",
            "Epoch 34/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1566 - accuracy: 0.9380 - val_loss: 1.1748 - val_accuracy: 0.6555\n",
            "Epoch 35/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1558 - accuracy: 0.9381 - val_loss: 1.1727 - val_accuracy: 0.6572\n",
            "Epoch 36/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1581 - accuracy: 0.9383 - val_loss: 1.2442 - val_accuracy: 0.6644\n",
            "Epoch 37/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1538 - accuracy: 0.9396 - val_loss: 1.2939 - val_accuracy: 0.6639\n",
            "Epoch 38/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1491 - accuracy: 0.9402 - val_loss: 1.2627 - val_accuracy: 0.6644\n",
            "Epoch 39/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1486 - accuracy: 0.9418 - val_loss: 1.2472 - val_accuracy: 0.6570\n",
            "Epoch 40/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.1419 - accuracy: 0.9438 - val_loss: 1.3016 - val_accuracy: 0.6623\n",
            "Epoch 41/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1434 - accuracy: 0.9442 - val_loss: 1.3097 - val_accuracy: 0.6580\n",
            "Epoch 42/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1396 - accuracy: 0.9448 - val_loss: 1.4195 - val_accuracy: 0.6583\n",
            "Epoch 43/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1444 - accuracy: 0.9430 - val_loss: 1.2972 - val_accuracy: 0.6578\n",
            "Epoch 44/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1424 - accuracy: 0.9459 - val_loss: 1.3719 - val_accuracy: 0.6585\n",
            "Epoch 45/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1357 - accuracy: 0.9489 - val_loss: 1.3507 - val_accuracy: 0.6659\n",
            "Epoch 46/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1379 - accuracy: 0.9456 - val_loss: 1.3146 - val_accuracy: 0.6628\n",
            "Epoch 47/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1364 - accuracy: 0.9465 - val_loss: 1.4014 - val_accuracy: 0.6636\n",
            "Epoch 48/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1352 - accuracy: 0.9445 - val_loss: 1.3616 - val_accuracy: 0.6611\n",
            "Epoch 49/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1313 - accuracy: 0.9477 - val_loss: 1.4157 - val_accuracy: 0.6626\n",
            "Epoch 50/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1246 - accuracy: 0.9523 - val_loss: 1.5117 - val_accuracy: 0.6659\n",
            "Epoch 51/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1279 - accuracy: 0.9501 - val_loss: 1.4864 - val_accuracy: 0.6700\n",
            "Epoch 52/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1268 - accuracy: 0.9500 - val_loss: 1.5538 - val_accuracy: 0.6583\n",
            "Epoch 53/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.1265 - accuracy: 0.9508 - val_loss: 1.5458 - val_accuracy: 0.6626\n",
            "Epoch 54/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1213 - accuracy: 0.9540 - val_loss: 1.5433 - val_accuracy: 0.6659\n",
            "Epoch 55/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1256 - accuracy: 0.9521 - val_loss: 1.5723 - val_accuracy: 0.6634\n",
            "Epoch 56/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1221 - accuracy: 0.9507 - val_loss: 1.5564 - val_accuracy: 0.6603\n",
            "Epoch 57/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1169 - accuracy: 0.9549 - val_loss: 1.5813 - val_accuracy: 0.6623\n",
            "Epoch 58/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1227 - accuracy: 0.9521 - val_loss: 1.5721 - val_accuracy: 0.6702\n",
            "Epoch 59/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.1218 - accuracy: 0.9530 - val_loss: 1.5830 - val_accuracy: 0.6656\n",
            "Epoch 60/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1153 - accuracy: 0.9563 - val_loss: 1.6235 - val_accuracy: 0.6613\n",
            "Epoch 61/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1153 - accuracy: 0.9543 - val_loss: 1.7467 - val_accuracy: 0.6720\n",
            "Epoch 62/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1129 - accuracy: 0.9570 - val_loss: 1.6577 - val_accuracy: 0.6560\n",
            "Epoch 63/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1122 - accuracy: 0.9554 - val_loss: 1.7700 - val_accuracy: 0.6537\n",
            "Epoch 64/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1145 - accuracy: 0.9564 - val_loss: 1.7215 - val_accuracy: 0.6606\n",
            "Epoch 65/80\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.1196 - accuracy: 0.9547 - val_loss: 1.5815 - val_accuracy: 0.6626\n",
            "Epoch 66/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1083 - accuracy: 0.9584 - val_loss: 1.7691 - val_accuracy: 0.6628\n",
            "Epoch 67/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1116 - accuracy: 0.9586 - val_loss: 1.6138 - val_accuracy: 0.6588\n",
            "Epoch 68/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1065 - accuracy: 0.9568 - val_loss: 1.7161 - val_accuracy: 0.6682\n",
            "Epoch 69/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1076 - accuracy: 0.9607 - val_loss: 1.7044 - val_accuracy: 0.6649\n",
            "Epoch 70/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1110 - accuracy: 0.9564 - val_loss: 1.7704 - val_accuracy: 0.6656\n",
            "Epoch 71/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1065 - accuracy: 0.9577 - val_loss: 1.8149 - val_accuracy: 0.6598\n",
            "Epoch 72/80\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.1063 - accuracy: 0.9571 - val_loss: 1.8651 - val_accuracy: 0.6659\n",
            "Epoch 73/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.1047 - accuracy: 0.9577 - val_loss: 1.8347 - val_accuracy: 0.6639\n",
            "Epoch 74/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1031 - accuracy: 0.9605 - val_loss: 1.8183 - val_accuracy: 0.6662\n",
            "Epoch 75/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1035 - accuracy: 0.9613 - val_loss: 1.8216 - val_accuracy: 0.6715\n",
            "Epoch 76/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.0983 - accuracy: 0.9609 - val_loss: 1.9253 - val_accuracy: 0.6664\n",
            "Epoch 77/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1019 - accuracy: 0.9600 - val_loss: 1.9104 - val_accuracy: 0.6634\n",
            "Epoch 78/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.0942 - accuracy: 0.9638 - val_loss: 2.0411 - val_accuracy: 0.6628\n",
            "Epoch 79/80\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.0995 - accuracy: 0.9614 - val_loss: 1.9355 - val_accuracy: 0.6682\n",
            "Epoch 80/80\n",
            "491/491 [==============================] - 2s 4ms/step - loss: 0.1028 - accuracy: 0.9603 - val_loss: 2.0301 - val_accuracy: 0.6613\n",
            "154/154 [==============================] - 0s 2ms/step\n",
            "DNN Accuracy (Bag of Words): 0.6551232430230189\n",
            "DNN F1 Score (Bag of Words): 0.5604771104464187\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}